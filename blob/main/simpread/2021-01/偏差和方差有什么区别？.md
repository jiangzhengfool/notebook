> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [www.zhihu.com](https://www.zhihu.com/question/20448464) ![](https://pic4.zhimg.com/87b9d6ac9_xs.jpg?source=1940ef5c)Jason Gu

**偏差：**描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据，如下图第二行所示。

**方差：**描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图右列所示。

![](https://pic2.zhimg.com/162bbe3ae6c8f46da4f4e05edea2d9fc_r.jpg?source=1940ef5c)参考：[Understanding the Bias-Variance Tradeoff](https://link.zhihu.com/?target=http%3A//scott.fortmann-roe.com/docs/BiasVariance.html)

 ![](https://pic2.zhimg.com/v2-ec067b8811e0a9f4af41f13423961097_xs.jpg?source=1940ef5c) 刑无刀

想象你开着一架黑鹰直升机，得到命令攻击地面上一只敌军部队，于是你连打数十梭子，结果有一下几种情况:  
1. 子弹基本上都打在队伍经过的一棵树上了，连在那棵树旁边等兔子的人都毫发无损，这就是方差小（子弹打得很集中），偏差大（跟目的相距甚远）。  
2. 子弹打在了树上，石头上，树旁边等兔子的人身上，花花草草也都中弹，但是敌军安然无恙，这就是方差大（子弹到处都是），偏差大（同 1）。  
3. 子弹打死了一部分敌军，但是也打偏了些打到花花草草了，这就是方差大（子弹不集中），偏差小（已经在目标周围了）。  
4. 子弹一颗没浪费，每一颗都打死一个敌军，跟抗战剧里的八路军一样，这就是方差小（子弹全部都集中在一个位置），偏差小（子弹集中的位置正是它应该射向的位置）。  

方差，是形容数据分散程度的，算是 “无监督的”，客观的指标，偏差，形容数据跟我们期望的中心差得有多远，算是 “有监督的”，有人的知识参与的指标。![](https://pic1.zhimg.com/3a2ee9df1223cc0adde52570f2c03b98_xs.jpg?source=1940ef5c)猩猩点灯

Bias：误差，对象是单个模型，期望输出与真实标记的差别

Variance：方差，对象是多个模型

从同一个数据集中，用科学的采样方法得到几个不同的子训练集，用这些训练集训练得到的模型往往并不相同。

![](https://pic3.zhimg.com/v2-54ed67557d663b895fe1d233e76641a7_r.jpg?source=1940ef5c)

以上图为例：  
1. 左上的模型偏差最大，右下的模型偏差最小；  
2. 左上的模型方差最小，右下的模型方差最大

为了理解第二点，可以看下图。蓝色和绿色分别是同一个训练集上采样得到的两个训练子集，由于采取了复杂的算法去拟合，两个模型差异很大。如果是拿直线拟合的话，显然差异不会这么大。

![](https://pic4.zhimg.com/50/f1108a741f95936a1a9e7435d8f89af3_hd.jpg?source=1940ef5c)

一般来说，偏差、方差和模型的复杂度之间的关系是这样子滴：

![](https://pic3.zhimg.com/50/e92560fbb3f3e853bfca02dae1d87c47_hd.jpg?source=1940ef5c)

实际中，我们需要找到偏差和方差都较小的点。

XGBOOST 中，我们选择尽可能多的树，尽可能深的层，来减少模型的偏差；  
通过 cross-validation，通过在验证集上校验，通过正则化，来减少模型的方差

从而获得较低的泛化误差。

![](https://pic1.zhimg.com/v2-ab64a9e4f2b6cf3f1ba10d2bcb89ab5e_xs.jpg?source=1940ef5c)工程师 milter

在机器学习的面试中，能不能讲清楚偏差方差，经常被用来考察面试者的理论基础。偏差方差看似很简单，但真要彻底地说明白，却有一定难度。比如，为什么 KNN 算法在增大 k 时，偏差会变大，但 RF 增大树的数目时偏差却保持不变，GBDT 在增大树的数目时偏差却又能变小。本文的目的就是希望能对偏差方差有一个科学的解读，欢迎大家多多交流。

1、引子

假设我们有一个回归问题，我们搞到一批训练数据 D，然后选择了一个模型 M，并用数据 D 将 M 训练出来，记作 Mt，这里我们故意把模型 M 与训练出的模型 Mt 区分开，是为了后面叙述时概念上的清晰。现在，我们怎么评价这个模型的好坏呢？

你可能会不屑地说，这么简单的问题还用问吗，当然是用 test 集来测试啊。

  

哈哈！你上当了！

  

因为我并没有说明是评价模型 M 的好坏还是模型 Mt 的好坏！这二者有什么区别呢？

我们都知道，模型 M 代表的是一个函数空间，比如模型 y=wx+b，若 x,y 都是实数，w,b 为实数参数，则该模型就代表了平面上所有的直线，这所有的直线就是一个函数空间。

同理，y=ax^2+bx+c 代表的就是平面上所有的二次曲线，所有的二次曲线组成一个函数空间。当然，所有的直线此时也是二次曲线的特例。

回到上面的问题，Mt 实际上是用数据 D 找到的 M 代表的函数空间中的一个具体的函数。这话有点绕，不过还是不难理解的。

Mt 的表现好坏不能完整地代表 M 的好坏。

上面这句话有很多内涵，我们一点一点来说明。

2、什么是 M 的好坏？

以上面的一次函数和二次函数为例，当我们说二次函数比一次函数更好时，我们潜在的含义是说，对于某个我们正要解决的机器学习问题来说，二次函数总体上比一次函数表现更好，我们是在函数空间的层次上来比较的。

而且，还是针对一个具体的机器学习问题来比较的，因为对于不同的机器学习问题，二者哪个更好是不一定的。

Note: 在下文中，可以把机器学习问题默想成回归问题，这样便于理解。

这里再次强调，当我们说模型好坏时，隐含有两个含义:

1, 比较的是整个函数空间

2, 针对某个具体机器学习问题比较

  

3，怎么比较 M 的好坏？

我们可以这样做:

1，找一条不变的万能测试样本

在这个具体的机器学习问题中找一条样本 x，它的标签为 y。在后续的所有训练中都用这条样本做测试集，永远不用作训练集。

2，在测试样本上观察 Mt 的表现，假设 Mt 在样本 x 上的预测值为 yt，则 y-yt 可用来评价 Mt 的表现好坏。

3，找另外一个训练集 D1，训练出 Mt1，在测试样本上测试得到 yt1，进而得到误差 y-yt1，

4，重复第 3 步多次，直到得到 N 个具体的模型，和 N 个 yt，N 个 y-yt。

5，当 N 足够大时，我们可以这样来评测 M 的好坏，首先看 N 个 yt 的均值 ytmean 是否等于 y，其次，看 N 个 yt 相对均值 ytmean 的方差有多大。

显然，若 ytmean=y，说明 M 学习能力是够的，也就是说，当 N 趋向无穷大时，N 个 Mt 对 x 预测的均值能无限接近 y。

很多人会有种错觉，感觉任何 M 都能达到上面的效果，实际上，不是每一个 M 都有这样的能力的，举个极端的例子，我们假设 M1 的函数空间中只有一个函数，且对于任何样本的预测值都恒等于 y+1，则无论 N 多大，ytmean 都会比 y 大 1 的。我们称 M1 由于学习能力不够所造成的对 x 的预测误差叫做偏差。

其次，N 个 yt 相对均值 ytmean 的方差有多大也能从另一个方面揭示 M 的好坏，举个例子，假设我们有 M1,M2 两个模型，当 N 无穷大时，都能使得 ytmean 等于 y。但是 M1 的预测值是这样分布的 (下面圆点代表一个个的预测值)

.....ytmean.....

M2 的预测值是这样分布的

. . . .ytmean. . . .

显然，我们会觉得 M1 比 M2 更好。你可能会想，N 足够大时，二者都能准确地均值到 y，这就够了，没必要再比较它们的预测值相对均值的方差。

这样的观点错误的地方是: 实践中，我们并不能抽样出 D1,D2,D3.......DN 个训练集，往往只有一份训练集 D，这种情况下，显然，用 M1 比用 M2 更有把握得到更小的误差。

4、举例子来说明偏差方差

假设模型是一个射击学习者，D1,D2 直到 DN 就是 N 个独立的训练计划。

如果一个学习者是正常人，一个眼睛斜视，则可以想见，斜视者无论参加多少训练计划，都不会打中靶心，问题不在训练计划够不够好，而在他的先天缺陷。这就是模型偏差产生的原因，学习能力不够。正常人参加 N 个训练计划后，虽然也不能保证打中靶心，但随着 N 的增大，会越来越接近靶心。

假设还有一个超级学习者，他的学习能力特别强，参加训练计划 D1 时，他不仅学会了瞄准靶心，还敏感地捕捉到了训练时的风速，光线，并据此调整了瞄准的方向，此时，他的训练成绩会很好。

但是，当参加测试时的光线，风速肯定与他训练时是不一样的，他仍然按照训练时学来的瞄准方法去打靶，肯定是打不好。这样产生的误差就是方差。这叫做聪明反被聪明误。

总结一下: 学习能力不行造成的误差是偏差，学习能力太强造成的误差是方差。

  

5、权衡偏差方差

当我们只有一份训练数据 D 时，我们选的 M 若太强，好比射手考虑太多风速，光线等因素，学出来的模型 Mt 在测试样本上表现肯定不好，若选择的 M 太挫，比如是斜视，也无论如何在测试的样本上表现也不会好。所以，最好的 M 就是学习能力刚刚好的射手，它能够刚刚好学习到瞄准的基本办法，又不会画蛇添足地学习太多细枝末节的东西。

  

6、回答本文最初的问题

对于 KNN 算法，k 值越大，表示模型的学习能力越弱，因为 k 越大，它越倾向于从 “面” 上考虑做出判断，而不是具体地考虑一个样本 近身的情况来做出判断，所以，它的偏差会越来越大。

对于 RF，我们实际上是部分实现了多次训练取均值的效果，每次训练得到的树都是一个很强的学习者，每一个的方差都比较大，但综合起来就会比较小。好比一个很强的学习者学习时，刮着西风，它会据此调整自己的瞄准方法，另一个很强的学习者学习时刮着东风，（西风、东风可以理解为不同训练集中的噪声）它也会据此调整自己的瞄准方法，在测试样本时，一个误差向西，一个误差向东，刚好起到互相抵消的作用，所以方差会比较小。但是由于每棵树的偏差都差不多，所以，我们取平均时，偏差不会怎么变化。

为什么说是部分实现了多次训练取均值的效果而不是全部呢？因为我们在训练各棵树时，是通过抽样样本集来实现多次训练的，不同的训练集中不可避免地会有重合的情况，此时，就不能认为是独立的多次训练了，各个训练得到的树之间的方差会产生一定的相关性，训练集中重合的样本越多，则两棵树之间的方差的相关性越强，就越难达成方差互相抵消的效果。

对于 GBDT，N 棵树之间根本就不是一种多次训练取均值的关系，而是 N 棵树组成了相关关联，层层递进的超级学习者，可想而知，它的方差一定是比较大的。但由于它的学习能力比较强，所以，它的偏差是很小的，而且树的棵树越多，学习能力就越强，偏差就越小。也就是说，只要学习次数够多，预测的均值会无限接近于目标。简单讲就是 GBDT 的 N 棵树实际上是一个有机关联的模型，不能认为是 N 个模型。

  
我是 milter，欢迎关注我的博客:  
[https://www.jianshu.com/u/511ba5d71aef](https://link.zhihu.com/?target=https%3A//www.jianshu.com/u/511ba5d71aef)![](https://pic1.zhimg.com/da8e974dc_xs.jpg?source=1940ef5c)「已注销」​

一、基本概念
------

1、偏差 bias

偏差是指预测结果与真实值之间的差异，排除噪声的影响，偏差更多的是针对某个模型输出的样本误差，偏差是模型无法准确表达数据关系导致，比如模型过于简单，非线性的数据关系采用线性模型建模，偏差较大的模型是错的模型；

2、方差 variance

模型方差不是针对某一个模型输出样本进行判定，而是指多个 (次) 模型输出的结果之间的离散差异，注意这里写的是多个模型或者多次模型，即不同模型或同一模型不同时间的输出结果方差较大，方差是由训练集的数据不够导致，一方面量 (数据量) 不够，有限的数据集过度训练导致模型复杂，另一方面质 (样本质量) 不行，测试集中的数据分布未在训练集中，导致每次抽样训练模型时，每次模型参数不同，输出的结果都无法准确的预测出正确结果；

二、为什么会有偏差和方差？
-------------

对学习算法除了通过实验估计其泛化性能之外，人们往往还希望了解它为什么具有这样的性能。**“偏差 - 方差分解”（bias-variance decomposition）**就是从偏差和方差的角度来解释学习算法泛化性能的一种重要工具。

在机器学习中，我们用训练数据集去训练一个模型，通常的做法是定义一个误差函数，通过将这个误差的最小化过程，来提高模型的性能。然而我们学习一个模型的目的是为了解决训练数据集这个领域中的一般化问题，单纯地将训练数据集的损失最小化，并不能保证在解决更一般的问题时模型仍然是最优，甚至不能保证模型是可用的。这个训练数据集的损失与一般化的数据集的损失之间的差异就叫做**泛化误差（generalization error）**。

而泛化误差可以分解为**偏差（Biase）**、**方差（Variance）**和**噪声（Noise）**。

如果我们能够获得所有可能的数据集合，并在这个数据集合上将损失最小化，那么学习得到的模型就可以称之为 **“真实模型”**。当然，在现实生活中我们不可能获取并训练所有可能的数据，所以 “真实模型” 肯定存在，但是无法获得。我们的最终目的是学习一个模型使其更加接近这个真实模型。

Bias 和 Variance 分别从两个方面来描述我们学习到的模型与真实模型之间的差距。

**Bias** 是用**所有可能的训练数据集**训练出的**所有模型**的输出的**平均值**与**真实模型**的输出值之间的差异。

**Variance** 是**不同的训练数据集训练出的模型**输出值之间的差异。

**噪声**的存在是学习算法所无法解决的问题，数据的质量决定了学习的上限。假设在数据已经给定的情况下，此时上限已定，我们要做的就是尽可能的接近这个上限。

**注意：**我们能够用来学习的训练数据集只是全部数据中的一个子集。想象一下，我们现在收集几组不同的数据，因为每一组数据的不同，我们学习到模型的最小损失值也会有所不同，它们与 “真实模型” 的最小损失也是不一样的。

**三、数学公式定义偏差、方差、噪声**
--------------------

要进一步理解偏差、方差、噪声，我们需要看看它们的数学公式。

![](https://pic1.zhimg.com/v2-c908aad493bd2e6233293546febb9aad_r.jpg?source=1940ef5c)

以回归任务为例，学习算法的期望预测为：

![](https://pic1.zhimg.com/50/v2-fb7e682bbb38abd7a5ebf96886fe6209_hd.jpg?source=1940ef5c)

这里的期望预测也就是针对不同数据集 D，模型 f 对样本 x 的预测值取其期望，也叫做**平均预测（average predicted）**。

（1）方差定义：

使用样本数相同的不同训练集产生的**方差**为：

![](https://pic4.zhimg.com/v2-616ca8f940a646edd0a0210a950433f2_r.jpg?source=1940ef5c)

**方差的含义：方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。**

（2）偏差定义：

期望输出与真实标记的差别称为**偏差（bias）**，即：

![](https://pic1.zhimg.com/50/v2-4adeb3da498dcbd1b8cec5e2da32cdeb_hd.jpg?source=1940ef5c)

**偏差的含义：偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。**

（3）噪声：

噪声为：

![](https://pic1.zhimg.com/50/v2-610467c3b8fe8c9158e3cd741fafa6b0_hd.jpg?source=1940ef5c)

**噪声的含义：噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。**

**我的理解：**偏差度量的是单个模型的学习能力，而方差度量的是同一个模型在不同数据集上的稳定性。

**四、 泛化误差、偏差和方差的关系？**
---------------------

![](https://pic2.zhimg.com/v2-45576822131959de50677a7632a42a89_r.jpg?source=1940ef5c)

也就是说，泛化误差可以通过一系列公式分解运算证明：泛化误差为偏差、方差与噪声之和。

证明过程如下：

为了便于讨论，我们假定噪声期望为零，即

![](https://pic2.zhimg.com/50/v2-3448b1004f72c7de4ddbaa7ae018af26_hd.jpg?source=1940ef5c)

通过简单的多项式展开合并，可对算法的期望泛化误差进行分解：

![](https://pic2.zhimg.com/v2-98896a23456ace9756c1847bd5763f65_r.jpg?source=1940ef5c)

于是，最终得到：

![](https://pic2.zhimg.com/v2-c21e566b695ba456f312ecc901e50282_r.jpg?source=1940ef5c)

**“偏差 - 方差分解” 说明**，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。

**五、用图形解释偏差和方差**
----------------

我们从下面的靶心图来对偏差和方差有个直观的感受。（图片来自：Understanding the Bias-Variance Tradeoff）  

![](https://pic2.zhimg.com/v2-6740d66757cd131a11f643667bbc3d19_r.jpg?source=1940ef5c)

假设红色的靶心区域是学习算法完美的正确预测值，蓝色点为训练数据集所训练出的模型对样本的预测值，当我们从靶心逐渐往外移动时，预测效果逐渐变差。

从上面的图片中很容易可以看到，左边一列的蓝色点比较集中，右边一列的蓝色点比较分散，它们描述的是方差的两种情况。比较集中的属于方差比较小，比较分散的属于方差比较大的情况。

我们再从蓝色点与红色靶心区域的位置关系来看，靠近红色靶心的属于偏差较小的情况，远离靶心的属于偏差较大的情况。

**思考：**从上面的图中可以看出，模型不稳定时会出现偏差小、方差大的情况，那么偏差和方差作为两种度量方式有什么区别呢？

**解答：**Bias 的对象是单个模型，是期望输出与真实标记的差别。它描述了模型对本训练集的拟合程度。Variance 的对象是多个模型，是相同分布的不同数据集训练出模型的输出值之间的差异。它刻画的是数据扰动对模型的影响。

**六、偏差、方差窘境**

一般来说，偏差与方差是有冲突的，这称为**偏差 - 方差窘境（bias-variance dilemma）**。下图给出了一个示意图。给定学习任务，假定我们能控制学习算法的训练程度，则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率；在训练程度充足后，学习器的拟合能力已经非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。

![](https://pic3.zhimg.com/v2-5a569cb13ad8c6d263460cb3c9c78cb5_r.jpg?source=1940ef5c)

  
七、**偏差、方差与过拟合、欠拟合的关系？**
--------------------------

一般来说，简单的模型会有一个较大的偏差和较小的方差，复杂的模型偏差较小方差较大。

欠拟合：模型不能适配训练样本，有一个很大的偏差。

举个例子：我们可能有本质上是多项式的连续非线性数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据不重要，因为模型根本无法表示数据的基本关系，模型不能适配训练样本，有一个很大的偏差，因此我们需要更复杂的模型。那么，是不是模型越复杂拟合程度越高越好呢？也不是，因为还有方差。

过拟合：模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。

方差就是指模型过于拟合训练数据，以至于没办法把模型的结果泛化。而泛化正是机器学习要解决的问题，如果一个模型只能对一组特定的数据有效，换了数据就无效，我们就说这个模型过拟合。这就是模型很好的适配训练样本，但在测试集上表现很糟，有一个很大的方差。

**八、偏差、方差与模型复杂度的关系**
--------------------

由前面偏差和方差的介绍，我们来总结一下**偏差和方差的来源**：我们训练的机器学习模型，必不可少地对数据依赖。但是，如果你不清楚数据服从一个什么样的分布，或是没办法拿到所有可能的数据（肯定拿不到所有数据），那么我们训练出来的模型和真实模型之间存在不一致性。这种不一致性表现在两个方面：偏差和方差。

那么，既然偏差和方差是这么来的，而且还是无法避免的，那么我们有什么办法尽量减少它对模型的影响呢？

一个好的办法就是正确选择模型的复杂度。复杂度高的模型通常对训练数据有很好的拟合能力，但是对测试数据就不一定了。而复杂度太低的模型又不能很好的拟合训练数据，更不能很好的拟合测试数据。因此，模型复杂度和模型偏差和方差具有如下图所示关系。

![](https://pic2.zhimg.com/v2-9c67941785eeefca8fb56de968eec236_r.jpg?source=1940ef5c)

**十、偏差、方差与 bagging、boosting 的关系？**
----------------------------------

**Bagging** 算法是对训练样本进行采样，产生出若干不同的子集，再从每个数据子集中训练出一个分类器，取这些分类器的平均，所以是降低模型的方差（variance）。Bagging 算法和 Random Forest 这种并行算法都有这个效果。

**Boosting** 则是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行权重调整，所以随着迭代不断进行，误差会越来越小，所以模型的偏差（bias）会不断降低。

**十一、偏差、方差和 K 折交叉验证的关系？**

K-fold Cross Validation 的思想：将原始数据分成 K 组 (一般是均分)，将每个子集数据分别做一次验证集，其余的 K-1 组子集数据作为训练集，这样会得到 K 个模型，用这 K 个模型最终的验证集的分类准确率的平均数作为此 K-CV 下分类器的性能指标。

对于一系列模型

![](https://pic2.zhimg.com/50/v2-83ab479a3ebbca91e42a86c4b413ab23_hd.jpg?source=1940ef5c)

，我们使用 Cross Validation 的目的是获得预测误差的无偏估计量 CV，从而可以用来选择一个最优的 Theta*, 使得 CV 最小。假设 K-folds cross validation，CV 统计量定义为每个子集中误差的平均值，**而 K 的大小和 CV 平均值的 bias 和 variance 是有关**的：

![](https://pic4.zhimg.com/50/v2-9f2a67a2d92d13f114dc9c1f4002db32_hd.jpg?source=1940ef5c)

其中，m = N/K 代表每个子集的大小， N 是总的训练样本量，K 是子集的数目。

当 K 较大时，m 较小，模型建立在较大的 N-m 上，经过更多次数的平均可以学习得到更符合真实数据分布的模型，Bias 就小了，但是这样一来模型就更加拟合训练数据集，再去测试集上预测的时候预测误差的期望值就变大了，从而 Variance 就大了；k 较小的时候，模型不会过度拟合训练数据，从而 Bias 较大，但是正因为没有过度拟合训练数据，Variance 也较小。

**十二、如何解决偏差、方差问题？**
-------------------

**整体思路：**首先，要知道偏差和方差是无法完全避免的，只能尽量减少其影响。

（1）在避免偏差时，需尽量选择正确的模型，一个非线性问题而我们一直用线性模型去解决，那无论如何，高偏差是无法避免的。

（2）有了正确的模型，我们还要慎重选择数据集的大小，通常数据集越大越好，但大到数据集已经对整体所有数据有了一定的代表性后，再多的数据已经不能提升模型了，反而会带来计算量的增加。而训练数据太小一定是不好的，这会带来过拟合，模型复杂度太高，方差很大，不同数据集训练出来的模型变化非常大。

（3）最后，要选择合适的模型复杂度，复杂度高的模型通常对训练数据有很好的拟合能力。

**针对偏差和方差的思路：**

**偏差：**实际上也可以称为避免欠拟合。

1、寻找更好的特征 -- 具有代表性。

2、用更多的特征 -- 增大输入向量的维度，增加模型复杂度。

**方差：**避免过拟合 。

1、增大数据集合 -- 使用更多的数据，减少数据扰动所造成的影响

2、减少数据特征 -- 减少数据维度，减少模型复杂度

3、正则化方法

4、交叉验证法